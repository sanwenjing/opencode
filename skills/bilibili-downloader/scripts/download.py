#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bilibiliè§†é¢‘ä¸‹è½½å™¨
ä½¿ç”¨ bilibili-api-python ç›´æ¥ä»Bç«™APIä¸‹è½½ï¼Œæ— éœ€æµè§ˆå™¨
å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œï¼Œè‡ªåŠ¨åˆå¹¶éŸ³è§†é¢‘
"""

# è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8
import sys
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import re
import os
import json
import asyncio
import urllib.request
import argparse
import subprocess
import shutil
import configparser
from typing import Optional, List, Dict
from bilibili_api import video, Credential


def extract_bvid(url: str) -> str:
    """ä»URLæå–BVå·"""
    if url.startswith('http'):
        match = re.search(r'BV[0-9a-zA-Z]{10,12}', url)
        if match:
            return match.group()
    else:
        return url
    return ''


def check_ffmpeg(auto_download: bool = True) -> Optional[str]:
    """æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å®‰è£…ffmpegï¼Œè¿”å›ffmpegè·¯å¾„"""
    # å°è¯•åœ¨PATHä¸­æŸ¥æ‰¾ffmpeg
    ffmpeg_path = shutil.which('ffmpeg')
    if ffmpeg_path:
        return ffmpeg_path
    
    # å°è¯•å¸¸è§è·¯å¾„
    possible_paths = [
        'C:\\ffmpeg\\bin\\ffmpeg.exe',
        'C:\\Program Files\\ffmpeg\\bin\\ffmpeg.exe',
        'C:\\Program Files (x86)\\ffmpeg\\bin\\ffmpeg.exe',
        '/usr/bin/ffmpeg',
        '/usr/local/bin/ffmpeg',
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    # å°è¯•æŸ¥æ‰¾å·²ä¸‹è½½çš„ä¾¿æºç‰ˆ
    local_ffmpeg = os.path.join(os.path.dirname(__file__), '..', 'ffmpeg', 'bin', 'ffmpeg.exe')
    if os.path.exists(local_ffmpeg):
        return local_ffmpeg
    
    # è‡ªåŠ¨ä¸‹è½½ffmpegï¼ˆä»…Windowsï¼‰
    if auto_download and sys.platform == 'win32':
        return download_ffmpeg_portable()
    
    return None


def download_ffmpeg_portable() -> Optional[str]:
    """è‡ªåŠ¨ä¸‹è½½ffmpegä¾¿æºç‰ˆï¼ˆWindowsï¼‰"""
    import zipfile
    import ssl
    
    try:
        print("\n[INFO] æ­£åœ¨è‡ªåŠ¨ä¸‹è½½ffmpegä¾¿æºç‰ˆ...")
        
        # ä¸‹è½½åˆ°æŠ€èƒ½ç›®å½•
        skill_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        ffmpeg_dir = os.path.join(skill_dir, 'ffmpeg')
        zip_path = os.path.join(ffmpeg_dir, 'ffmpeg.zip')
        
        # åˆ›å»ºç›®å½•
        os.makedirs(ffmpeg_dir, exist_ok=True)
        
        # ä¸‹è½½åœ°å€
        url = "https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip"
        
        # ç¦ç”¨SSLéªŒè¯
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE
        
        print(f"[INFO] ä¸‹è½½ffmpeg...")
        print(f"[INFO] ç›®æ ‡: {ffmpeg_dir}")
        
        # ä¸‹è½½
        req = urllib.request.Request(
            url,
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        )
        
        with urllib.request.urlopen(req, context=ssl_context, timeout=120) as response:
            with open(zip_path, 'wb') as f:
                f.write(response.read())
        
        print("[INFO] è§£å‹ä¸­...")
        
        # è§£å‹
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(ffmpeg_dir)
        
        # æŸ¥æ‰¾ffmpeg.exe
        for root, dirs, files in os.walk(ffmpeg_dir):
            if 'ffmpeg.exe' in files:
                exe_path = os.path.join(root, 'ffmpeg.exe')
                
                # ç§»åŠ¨åˆ°æ ‡å‡†ä½ç½®
                bin_dir = os.path.join(ffmpeg_dir, 'bin')
                os.makedirs(bin_dir, exist_ok=True)
                
                final_path = os.path.join(bin_dir, 'ffmpeg.exe')
                shutil.copy2(exe_path, final_path)
                
                # æ¸…ç†
                try:
                    os.remove(zip_path)
                    # åˆ é™¤ä¸´æ—¶è§£å‹ç›®å½•
                    for d in dirs:
                        shutil.rmtree(os.path.join(root, d), ignore_errors=True)
                except:
                    pass
                
                print(f"[SUCCESS] ffmpegä¸‹è½½æˆåŠŸ: {final_path}")
                return final_path
        
        return None
        
    except Exception as e:
        print(f"[WARNING] è‡ªåŠ¨ä¸‹è½½ffmpegå¤±è´¥: {e}")
        return None


def install_ffmpeg_guide():
    """æ˜¾ç¤ºffmpegå®‰è£…æŒ‡å—"""
    print("\n" + "=" * 70)
    print("[INFO] æœªæ£€æµ‹åˆ°ffmpegï¼Œéœ€è¦å®‰è£…æ‰èƒ½è‡ªåŠ¨åˆå¹¶éŸ³è§†é¢‘")
    print("=" * 70)
    print("\nWindowså®‰è£…æ–¹æ³•:")
    print("1. è®¿é—® https://ffmpeg.org/download.html")
    print("2. ä¸‹è½½Windowsç‰ˆæœ¬å¹¶è§£å‹åˆ°C:\\ffmpeg")
    print("3. å°†C:\\ffmpeg\\binæ·»åŠ åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡PATH")
    print("4. é‡å¯å‘½ä»¤è¡Œçª—å£")
    print("\næˆ–ä½¿ç”¨åŒ…ç®¡ç†å™¨å®‰è£…:")
    print("  - Windows (choco): choco install ffmpeg")
    print("  - Windows (scoop): scoop install ffmpeg")
    print("  - Mac (brew): brew install ffmpeg")
    print("  - Linux (apt): sudo apt install ffmpeg")
    print("=" * 70)


def merge_video_audio(video_path: str, audio_path: str, output_path: str, ffmpeg_path: Optional[str] = None) -> bool:
    """
    ä½¿ç”¨ffmpegåˆå¹¶éŸ³è§†é¢‘
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        ffmpeg_path: ffmpegå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        åˆå¹¶æ˜¯å¦æˆåŠŸ
    """
    if not ffmpeg_path:
        ffmpeg_path = check_ffmpeg()
    
    if not ffmpeg_path:
        print("\n[ERROR] æœªæ‰¾åˆ°ffmpegï¼Œæ— æ³•è‡ªåŠ¨åˆå¹¶")
        install_ffmpeg_guide()
        return False
    
    try:
        print(f"\n[INFO] æ­£åœ¨åˆå¹¶éŸ³è§†é¢‘...")
        print(f"[INFO] ä½¿ç”¨ffmpeg: {ffmpeg_path}")
        
        # æ„å»ºffmpegå‘½ä»¤
        cmd = [
            ffmpeg_path,
            '-i', video_path,
            '-i', audio_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-strict', 'experimental',
            '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            output_path
        ]
        
        print(f"[INFO] æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace'
        )
        
        if result.returncode == 0:
            # åˆå¹¶æˆåŠŸï¼Œåˆ é™¤åŸæ–‡ä»¶
            print("[INFO] åˆå¹¶æˆåŠŸï¼Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
            try:
                os.remove(video_path)
                os.remove(audio_path)
                print(f"[INFO] å·²åˆ é™¤: {os.path.basename(video_path)}")
                print(f"[INFO] å·²åˆ é™¤: {os.path.basename(audio_path)}")
            except Exception as e:
                print(f"[WARNING] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
            
            return True
        else:
            print(f"[ERROR] åˆå¹¶å¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"[ERROR] åˆå¹¶è¿‡ç¨‹å‡ºé”™: {e}")
        return False


def load_credential():
    """
    åŠ è½½Bç«™ç™»å½•å‡­è¯ï¼ˆæ”¯æŒcookiesé…ç½®ï¼‰
    
    é…ç½®æ–‡ä»¶æ ¼å¼ (config.ini):
    [bilibili]
    # æ–¹å¼1: å®Œæ•´çš„Cookieå­—ç¬¦ä¸²ï¼ˆæ¨èï¼Œä»æµè§ˆå™¨å¤åˆ¶ï¼‰
    cookie = å®Œæ•´çš„cookieå­—ç¬¦ä¸²
    
    # æ–¹å¼2: åˆ†åˆ«å¡«å…¥å„å­—æ®µ
    sessdata = ä½ çš„SESSDATAå€¼
    buvid3 = ä½ çš„BUVID3å€¼
    bili_jct = ä½ çš„BILI_JCTå€¼
    
    è·å–æ–¹æ³•ï¼š
    1. ç™»å½•Bç«™ç½‘é¡µç‰ˆ (https://www.bilibili.com)
    2. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…·
    3. åˆ‡æ¢åˆ°Network(ç½‘ç»œ)æ ‡ç­¾
    4. åˆ·æ–°é¡µé¢ï¼Œç‚¹å‡»ä»»æ„è¯·æ±‚ï¼ˆå¦‚www.bilibili.comï¼‰
    5. åœ¨Request Headersä¸­æ‰¾åˆ°Cookieå­—æ®µ
    6. å¤åˆ¶æ•´ä¸ªCookieå€¼
    """
    config_path = os.path.join(os.path.dirname(__file__), '..', 'config.ini')
    
    if not os.path.exists(config_path):
        print("[INFO] æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶config.iniï¼Œå°†ä½¿ç”¨æœªç™»å½•çŠ¶æ€ä¸‹è½½ï¼ˆç”»è´¨å—é™ï¼‰")
        print("[INFO] å¦‚éœ€ä¸‹è½½é«˜æ¸…ç”»è´¨ï¼Œè¯·åˆ›å»ºé…ç½®æ–‡ä»¶config.ini")
        print("[INFO] é…ç½®æ–‡ä»¶è·¯å¾„:", os.path.normpath(config_path))
        return None
    
    try:
        # ç›´æ¥è¯»å–æ–‡ä»¶ï¼Œæ‰‹åŠ¨è§£æ
        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ‰‹åŠ¨è§£æiniæ–‡ä»¶
        cookie = ''
        sessdata = ''
        buvid3 = ''
        bili_jct = ''
        
        in_bilibili_section = False
        for line in content.split('\n'):
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            if line.startswith('[') and line.endswith(']'):
                in_bilibili_section = (line == '[bilibili]')
                continue
            if in_bilibili_section and '=' in line:
                key, value = line.split('=', 1)
                key = key.strip().lower()
                value = value.strip()
                if key == 'cookie':
                    cookie = value
                elif key == 'sessdata':
                    sessdata = value
                elif key == 'buvid3':
                    buvid3 = value
                elif key == 'bili_jct':
                    bili_jct = value
        
        if cookie:
            # ä»å®Œæ•´cookieå­—ç¬¦ä¸²ä¸­æå–å„å­—æ®µ
            for item in cookie.split(';'):
                item = item.strip()
                if item.startswith('SESSDATA='):
                    sessdata = item.split('=')[1]
                elif item.startswith('buvid3='):
                    buvid3 = item.split('=')[1]
                elif item.startswith('bili_jct='):
                    bili_jct = item.split('=')[1]
            
            if not sessdata or not buvid3 or not bili_jct:
                print("[WARNING] Cookieæ ¼å¼ä¸å®Œæ•´ï¼Œéœ€è¦åŒ…å«SESSDATA, buvid3, bili_jct")
                return None
            
            cred = Credential(sessdata=sessdata, buvid3=buvid3, bili_jct=bili_jct)
            return cred
        
        if not sessdata or not buvid3 or not bili_jct:
            print("[WARNING] é…ç½®é¡¹ä¸å®Œæ•´ï¼Œéœ€è¦sessdata, buvid3, bili_jct")
            return None
        
        cred = Credential(sessdata=sessdata, buvid3=buvid3, bili_jct=bili_jct)
        return cred
        
    except Exception as e:
        print(f"[WARNING] åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None


async def verify_credential(credential: Credential) -> tuple:
    """
    éªŒè¯å‡­è¯æ˜¯å¦æœ‰æ•ˆ
    
    Returns:
        (is_valid, vip_status, level)
    """
    try:
        # å°è¯•è®¿é—®éœ€è¦ç™»å½•çš„APIæ¥éªŒè¯å‡­è¯
        from bilibili_api import video
        v = video.Video(bvid='BV1ux411c7h8', credential=credential)
        info = await v.get_info()
        
        if info and info.get('owner'):
            # å‡­è¯æœ‰æ•ˆ
            return True, False, 0
        
        return False, False, 0
        
    except Exception as e:
        error_str = str(e).lower()
        if 'auth' in error_str or 'login' in error_str or 'credential' in error_str or '403' in error_str:
            return False, False, 0
        # å…¶ä»–é”™è¯¯å¯èƒ½åªæ˜¯è§†é¢‘ä¸å­˜åœ¨ï¼Œä½†å‡­è¯å¯èƒ½æœ‰æ•ˆ
        return True, False, 0
    
    try:
        config = configparser.ConfigParser()
        config.read(config_path, encoding='utf-8')
        
        if 'bilibili' not in config:
            print("[WARNING] é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘[bilibili] section")
            return None
        
        # ä¼˜å…ˆä½¿ç”¨å®Œæ•´cookieå­—æ®µ
        cookie = config.get('bilibili', 'cookie', fallback='').strip()
        
        if cookie:
            # ä»å®Œæ•´cookieå­—ç¬¦ä¸²ä¸­æå–å„å­—æ®µ
            sessdata = ''
            buvid3 = ''
            bili_jct = ''
            
            for item in cookie.split(';'):
                item = item.strip()
                if item.startswith('SESSDATA='):
                    sessdata = item.split('=')[1]
                elif item.startswith('buvid3='):
                    buvid3 = item.split('=')[1]
                elif item.startswith('bili_jct='):
                    bili_jct = item.split('=')[1]
            
            if not sessdata or not buvid3 or not bili_jct:
                print("[WARNING] Cookieæ ¼å¼ä¸å®Œæ•´ï¼Œéœ€è¦åŒ…å«SESSDATA, buvid3, bili_jct")
                return None
            
            print("[INFO] å·²ä»å®Œæ•´CookieåŠ è½½ç™»å½•å‡­è¯")
            cred = Credential(sessdata=sessdata, buvid3=buvid3, bili_jct=bili_jct)
            print("[INFO] å°†å°è¯•ä¸‹è½½é«˜æ¸…ç”»è´¨")
            return cred
        
        # å…¼å®¹æ—§æ–¹å¼ï¼šåˆ†åˆ«å¡«å†™å„å­—æ®µ
        sessdata = config.get('bilibili', 'sessdata', fallback='').strip()
        buvid3 = config.get('bilibili', 'buvid3', fallback='').strip()
        bili_jct = config.get('bilibili', 'bili_jct', fallback='').strip()
        
        if not sessdata or not buvid3 or not bili_jct:
            print("[WARNING] é…ç½®é¡¹ä¸å®Œæ•´ï¼Œéœ€è¦sessdata, buvid3, bili_jct")
            return None
        
        cred = Credential(sessdata=sessdata, buvid3=buvid3, bili_jct=bili_jct)
        print("[INFO] å·²åŠ è½½ç™»å½•å‡­è¯ï¼Œå°†å°è¯•ä¸‹è½½é«˜æ¸…ç”»è´¨")
        return cred
        
    except Exception as e:
        print(f"[WARNING] åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None


def get_video_codecs(download_info: dict) -> List[Dict]:
    """è·å–å¯ç”¨çš„è§†é¢‘ç¼–ç åˆ—è¡¨"""
    codecs = []
    if 'dash' in download_info and 'video' in download_info['dash']:
        for v in download_info['dash']['video']:
            codecs.append({
                'id': v.get('id'),
                'codecs': v.get('codecs', ''),
                'bandwidth': v.get('bandwidth', 0),
                'baseUrl': v.get('baseUrl', v.get('base_url', ''))
            })
    return codecs


def get_quality_name(quality_id: int) -> str:
    """å°†ç”»è´¨IDè½¬æ¢ä¸ºå¯è¯»åç§°"""
    quality_map = {
        6: '240P',
        16: '360P',
        32: '480P',
        48: '720P',
        64: '720P+',
        74: '1080P',
        80: '1080P+',
        112: '4K',
    }
    return quality_map.get(quality_id, f'{quality_id}P')


def select_best_video_stream(urls: list) -> Optional[Dict]:
    """
    é€‰æ‹©æœ€ä½³è§†é¢‘æµ
    ä¼˜å…ˆçº§ï¼š
    1. æŒ‰ç”»è´¨idé€‰æ‹©æœ€é«˜ï¼ˆidè¶Šå¤§ç”»è´¨è¶Šå¥½ï¼š16=360P, 32=480P, 64=720P, 80=1080Pï¼‰
    2. åŒç”»è´¨ä¸‹ä¼˜å…ˆH.264ç¼–ç ï¼ˆå…¼å®¹æ€§æœ€å¥½ï¼‰
    3. æ’é™¤AV1ç­‰å¯èƒ½ä¸å…¼å®¹çš„ç¼–ç 
    """
    video_streams = [u for u in urls if u['type'] == 'video']
    
    if not video_streams:
        return None
    
    # æŒ‰ç”»è´¨idåˆ†ç»„
    quality_groups = {}
    for v in video_streams:
        qid = v.get('quality', 0)
        if qid not in quality_groups:
            quality_groups[qid] = []
        quality_groups[qid].append(v)
    
    # é€‰æ‹©æœ€é«˜ç”»è´¨
    if not quality_groups:
        return None
    
    highest_quality = max(quality_groups.keys())
    highest_streams = quality_groups[highest_quality]
    
    # åœ¨æœ€é«˜ç”»è´¨ä¸­ä¼˜å…ˆé€‰æ‹©H.264ç¼–ç 
    h264_streams = [v for v in highest_streams if 'avc' in v.get('codecs', '').lower()]
    
    if h264_streams:
        # è¿”å›å¸¦å®½æœ€é«˜çš„
        return max(h264_streams, key=lambda x: x.get('bandwidth', 0))
    
    # å¦‚æœæ²¡æœ‰H.264ï¼Œæ’é™¤AV1
    valid_streams = [v for v in highest_streams if 'av01' not in v.get('codecs', '').lower()]
    if valid_streams:
        return max(valid_streams, key=lambda x: x.get('bandwidth', 0))
    
    # è¿”å›æœ€é«˜ç”»è´¨çš„ç¬¬ä¸€ä¸ª
    return highest_streams[0]


async def download_video(bvid: str, output_dir: Optional[str] = None, auto_merge: bool = True, page_index: Optional[int] = None, threads: int = 3):
    """
    ä¸‹è½½è§†é¢‘çš„å®Œæ•´æµç¨‹

    Args:
        bvid: BVå·
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•çš„downloadsæ–‡ä»¶å¤¹ï¼‰
        auto_merge: æ˜¯å¦è‡ªåŠ¨åˆå¹¶éŸ³è§†é¢‘ï¼ˆé»˜è®¤Trueï¼‰
        page_index: æŒ‡å®šåˆ†Pç´¢å¼•ï¼ˆNoneè¡¨ç¤ºä¸‹è½½æ‰€æœ‰åˆ†Pï¼‰
        threads: å¹¶è¡Œä¸‹è½½çš„çº¿ç¨‹æ•°ï¼ˆé»˜è®¤3ï¼‰
    """
    # ç¡®ä¿output_diræ˜¯ç»å¯¹è·¯å¾„ï¼Œä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
    if output_dir is None:
        output_dir = os.path.abspath(os.path.join(os.getcwd(), 'downloads'))
    elif not os.path.isabs(output_dir):
        output_dir = os.path.abspath(output_dir)
    
    print("=" * 70)
    print("Bilibiliè§†é¢‘ä¸‹è½½å™¨")
    print("=" * 70)
    print(f"BVå·: {bvid}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"è‡ªåŠ¨åˆå¹¶: {'æ˜¯' if auto_merge else 'å¦'}")
    print("=" * 70)
    
    # æ£€æŸ¥ffmpegï¼ˆå¦‚æœéœ€è¦è‡ªåŠ¨åˆå¹¶ï¼‰
    ffmpeg_path = None
    if auto_merge:
        ffmpeg_path = check_ffmpeg()
        if ffmpeg_path:
            print(f"[INFO] æ£€æµ‹åˆ°ffmpeg: {ffmpeg_path}")
        else:
            print("[WARNING] æœªæ£€æµ‹åˆ°ffmpegï¼Œå°†åªæä¾›åˆå¹¶å‘½ä»¤")
    
    # åŠ è½½ç™»å½•å‡­è¯
    credential = load_credential()
    
    # éªŒè¯å‡­è¯æœ‰æ•ˆæ€§
    if credential:
        print("\n[INFO] æ­£åœ¨éªŒè¯ç™»å½•å‡­è¯...")
        is_valid, is_vip, level = await verify_credential(credential)
        
        if not is_valid:
            print("\n" + "=" * 70)
            print("[WARNING] âš ï¸ ç™»å½•å‡­è¯å·²å¤±æ•ˆï¼")
            print("=" * 70)
            print("[INFO] è¯·é‡æ–°è·å–Cookieï¼š")
            print("  1. ç™»å½•Bç«™ç½‘é¡µç‰ˆ (https://www.bilibili.com)")
            print("  2. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…·")
            print("  3. åˆ‡æ¢åˆ°Network(ç½‘ç»œ)æ ‡ç­¾")
            print("  4. åˆ·æ–°é¡µé¢")
            print("  5. ç‚¹å‡»ä»»æ„è¯·æ±‚ï¼Œå¤åˆ¶Cookieå€¼")
            print("  6. æ›´æ–°é…ç½®æ–‡ä»¶:", os.path.normpath(os.path.join(os.path.dirname(__file__), '..', 'config.ini')))
            print("=" * 70)
            credential = None
        else:
            print(f"[INFO] âœ“ ç™»å½•å‡­è¯æœ‰æ•ˆ (ç”¨æˆ·ç­‰çº§: {level})")
            if is_vip:
                print("[INFO] âœ“ æ£€æµ‹åˆ°å¤§ä¼šå‘˜ï¼Œå¯ä»¥ä¸‹è½½1080P+é«˜æ¸…ç”»è´¨")
    
    # 1. è·å–è§†é¢‘ä¿¡æ¯
    print("\n[INFO] è·å–è§†é¢‘ä¿¡æ¯...")
    v = video.Video(bvid=bvid, credential=credential)
    info = await v.get_info()
    
    title = info.get('title', 'unknown')
    owner = info.get('owner', {}).get('name', 'unknown')
    duration = info.get('duration', 0)
    
    print(f"[INFO] æ ‡é¢˜: {title}")
    print(f"[INFO] UPä¸»: {owner}")
    print(f"[INFO] æ—¶é•¿: {duration}ç§’")
    
    # è·å–æ‰€æœ‰åˆ†Pä¿¡æ¯
    pages = info.get('pages', [])
    print(f"[INFO] å…±æœ‰ {len(pages)} ä¸ªåˆ†P")
    
    # ç¡®å®šè¦ä¸‹è½½çš„åˆ†Påˆ—è¡¨
    if page_index is not None:
        if page_index < 0 or page_index >= len(pages):
            print(f"[ERROR] æ— æ•ˆçš„åˆ†Pç´¢å¼•: {page_index}")
            return False
        page_list = [page_index]
    else:
        page_list = list(range(len(pages)))
    
    print(f"[INFO] å°†ä¸‹è½½ {len(page_list)} ä¸ªè§†é¢‘")
    
    # åˆ›å»ºä¸»è¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    # æ–‡ä»¶å¤¹å‘½åï¼šæ—¶é—´æˆ³+åŸå§‹æ ‡é¢˜
    from datetime import datetime
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    safe_title = re.sub(r'[\\/:*?"<>|]', '', title)
    safe_title = safe_title.strip()
    # æˆªå–æ ‡é¢˜å‰30å­—ç¬¦
    if len(safe_title) > 30:
        safe_title = safe_title[:30].strip()
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²ä¸‹è½½çš„æ–‡ä»¶å¤¹ï¼ˆåŒ…å«è¯¥è§†é¢‘æ ‡é¢˜çš„æ–‡ä»¶å¤¹ï¼‰
    target_folder_name = f"{safe_title}"
    existing_folder = None
    
    if os.path.exists(output_dir):
        for folder in os.listdir(output_dir):
            if target_folder_name in folder and os.path.isdir(os.path.join(output_dir, folder)):
                existing_folder = os.path.join(output_dir, folder)
                break
    
    if existing_folder:
        main_output_dir = existing_folder
        print(f"[INFO] æ£€æµ‹åˆ°å·²å­˜åœ¨çš„ä¸‹è½½æ–‡ä»¶å¤¹ï¼Œä½¿ç”¨ç°æœ‰æ–‡ä»¶å¤¹: {os.path.basename(main_output_dir)}")
    else:
        main_output_dir = os.path.join(output_dir, f"{timestamp}{safe_title}")
        os.makedirs(main_output_dir, exist_ok=True)
    
    # 2. ä¸‹è½½æ¯ä¸ªåˆ†P
    total_pages = len(page_list)
    
    # æ˜¾ç¤ºçº¿ç¨‹æ•°ä¿¡æ¯
    if total_pages > 1:
        print(f"[INFO] å°†ä½¿ç”¨ {min(threads, total_pages)} ä¸ªçº¿ç¨‹å¹¶è¡Œä¸‹è½½ {total_pages} ä¸ªè§†é¢‘")
    
    async def download_single_video(idx: int, page_idx: int, semaphore: asyncio.Semaphore, max_retries: int = 3) -> tuple:
        """ä¸‹è½½å•ä¸ªè§†é¢‘çš„å¼‚æ­¥å‡½æ•°ï¼Œæ”¯æŒé‡è¯•"""
        page_info = pages[page_idx]
        page_title = page_info.get('part', f'P{page_idx + 1}')
        error_msg = "æœªçŸ¥é”™è¯¯"
        
        for retry_count in range(max_retries):
            async with semaphore:
                success = True
                error_msg = ""
                
                try:
                    retry_prefix = f"[é‡è¯• {retry_count + 1}/{max_retries}]" if retry_count > 0 else ""
                    print(f"\n{'='*70}")
                    print(f"{retry_prefix}[INFO] ä¸‹è½½ç¬¬ {idx}/{total_pages} ä¸ªè§†é¢‘ (åˆ†P {page_idx + 1}): {page_title}")
                    print(f"{'='*70}")
                    
                    if retry_count > 0:
                        print(f"[INFO] ç­‰å¾…3ç§’åé‡è¯•...")
                        await asyncio.sleep(3)
                    
                    # è·å–ä¸‹è½½é“¾æ¥
                    download_info = await v.get_download_url(page_index=page_idx)
                    
                    urls = []
                    
                    # è§£æDASHæ ¼å¼
                    if 'dash' in download_info:
                        dash = download_info['dash']
                        
                        # è§†é¢‘æµ
                        if 'video' in dash:
                            for v_stream in dash['video']:
                                urls.append({
                                    'url': v_stream.get('baseUrl', v_stream.get('base_url', '')),
                                    'quality': v_stream.get('id', 0),
                                    'bandwidth': v_stream.get('bandwidth', 0),
                                    'codecs': v_stream.get('codecs', ''),
                                    'type': 'video'
                                })
                        
                        # éŸ³é¢‘æµ
                        if 'audio' in dash:
                            for a_stream in dash['audio']:
                                urls.append({
                                    'url': a_stream.get('baseUrl', a_stream.get('base_url', '')),
                                    'quality': a_stream.get('id', 0),
                                    'bandwidth': a_stream.get('bandwidth', 0),
                                    'type': 'audio'
                                })
                    
                    if not urls:
                        success = False
                        error_msg = "æœªæ‰¾åˆ°ä¸‹è½½é“¾æ¥"
                        if retry_count < max_retries - 1:
                            continue
                        return success, error_msg
                    
                    # åˆ†ç¦»éŸ³è§†é¢‘
                    video_streams = [u for u in urls if u['type'] == 'video']
                    audio_streams = [u for u in urls if u['type'] == 'audio']
                    
                    if not video_streams or not audio_streams:
                        success = False
                        error_msg = "æœªæ‰¾åˆ°å®Œæ•´çš„éŸ³è§†é¢‘æµ"
                        if retry_count < max_retries - 1:
                            continue
                        return success, error_msg
                    
                    # é€‰æ‹©æœ€ä½³è§†é¢‘æµ
                    best_video = select_best_video_stream(urls)
                    
                    if not best_video:
                        success = False
                        error_msg = "æ— æ³•é€‰æ‹©æœ‰æ•ˆçš„è§†é¢‘æµ"
                        if retry_count < max_retries - 1:
                            continue
                        return success, error_msg
                    
                    best_audio = max(audio_streams, key=lambda x: x['bandwidth'])
                    
                    quality_name = get_quality_name(best_video.get('quality', 0))
                    print(f"[INFO] è§†é¢‘ç”»è´¨: {quality_name} (ID: {best_video.get('quality', 0)})")
                    print(f"[INFO] è§†é¢‘ç¼–ç : {best_video.get('codecs', 'unknown')}")
                    
                    # å‡†å¤‡æ–‡ä»¶åï¼ˆæ ¼å¼ï¼š01.æ ‡é¢˜.mp4ï¼‰
                    page_num = page_idx + 1
                    safe_page_title = re.sub(r'[\\/:*?"<>|ï¼Œã€‚ï¼ˆï¼‰()ï¼!]', '', page_title)
                    safe_page_title = safe_page_title.strip()
                    if len(safe_page_title) > 30:
                        safe_page_title = safe_page_title[:30].strip()
                    safe_page_title = re.sub(r'^\d+[\.ï¼]', '', safe_page_title)
                    p_safe_title = f"{page_num:02d}.{safe_page_title}"
                    
                    # ä¸‹è½½è§†é¢‘
                    video_filename = f"{p_safe_title}_video.mp4"
                    video_path = os.path.join(main_output_dir, video_filename)
                    audio_filename = f"{p_safe_title}_audio.m4a"
                    audio_path = os.path.join(main_output_dir, audio_filename)
                    final_filename = f"{p_safe_title}.mp4"
                    final_path = os.path.join(main_output_dir, final_filename)
                    
                    # æ£€æŸ¥æœ€ç»ˆæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆä¸‹è½½å®Œæˆï¼‰
                    if os.path.exists(final_path):
                        print(f"â­ï¸ åˆ†P {page_idx + 1} å·²ä¸‹è½½å®Œæˆï¼Œè·³è¿‡: {final_filename}")
                        return True, ""
                    
                    # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    video_exists = os.path.exists(video_path)
                    audio_exists = os.path.exists(audio_path)
                    
                    if video_exists and audio_exists:
                        print(f"â­ï¸ åˆ†P {page_idx + 1} éŸ³è§†é¢‘å·²ä¸‹è½½ï¼Œæ­£åœ¨åˆå¹¶...")
                        if auto_merge and ffmpeg_path:
                            merge_success = merge_video_audio(video_path, audio_path, final_path, ffmpeg_path)
                            if merge_success:
                                print(f"âœ“ åˆ†P {page_idx + 1} ä¸‹è½½å®Œæˆ: {final_filename}")
                                return True, ""
                    
                    print(f"[INFO] ä¸‹è½½è§†é¢‘...")
                    if not download_file(best_video['url'], video_path):
                        success = False
                        error_msg = "ä¸‹è½½è§†é¢‘å¤±è´¥"
                        if retry_count < max_retries - 1:
                            continue
                        return success, error_msg
                    
                    print(f"[INFO] ä¸‹è½½éŸ³é¢‘...")
                    if not download_file(best_audio['url'], audio_path):
                        success = False
                        error_msg = "ä¸‹è½½éŸ³é¢‘å¤±è´¥"
                        if retry_count < max_retries - 1:
                            continue
                        return success, error_msg
                    
                    # åˆå¹¶éŸ³è§†é¢‘
                    if auto_merge and ffmpeg_path:
                        merge_success = merge_video_audio(video_path, audio_path, final_path, ffmpeg_path)
                        if merge_success:
                            print(f"âœ“ åˆ†P {page_idx + 1} ä¸‹è½½å®Œæˆ: {final_filename}")
                        else:
                            print(f"âœ“ åˆ†P {page_idx + 1} ä¸‹è½½å®Œæˆï¼ˆæœªåˆå¹¶ï¼‰: {video_filename}, {audio_filename}")
                    else:
                        print(f"âœ“ åˆ†P {page_idx + 1} ä¸‹è½½å®Œæˆ: {video_filename}, {audio_filename}")
                    
                    return success, error_msg
                    
                except Exception as e:
                    print(f"[ERROR] ä¸‹è½½åˆ†P {page_idx + 1} å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    error_msg = str(e)
                    if retry_count < max_retries - 1:
                        print(f"[INFO] å°†åœ¨3ç§’åè¿›è¡Œç¬¬{retry_count + 2}æ¬¡é‡è¯•...")
                        await asyncio.sleep(3)
                        continue
                    return False, error_msg
        
        return False, error_msg
    
    # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(min(threads, total_pages))
    
    # åˆ›å»ºæ‰€æœ‰ä¸‹è½½ä»»åŠ¡
    tasks = []
    for idx, page_idx in enumerate(page_list, 1):
        task = download_single_video(idx, page_idx, semaphore)
        tasks.append(task)
    
    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # ç»Ÿè®¡ç»“æœ
    success_count = 0
    fail_count = 0
    
    for i, result in enumerate(results):
        if isinstance(result, tuple) and result[0]:
            success_count += 1
        else:
            fail_count += 1
    
    # 3. å®Œæˆæ€»ç»“
    print(f"\n{'='*70}")
    print("ä¸‹è½½å®Œæˆï¼")
    print("=" * 70)
    print(f"æ€»è§†é¢‘æ•°: {total_pages}")
    print(f"æˆåŠŸä¸‹è½½: {success_count}")
    print(f"å¤±è´¥æ•°é‡: {fail_count}")
    print(f"ä¿å­˜ç›®å½•: {main_output_dir}")
    print("=" * 70)
    
    return success_count > 0


def download_file(url: str, file_path: str, check_existing: bool = True) -> bool:
    """ä¸‹è½½å•ä¸ªæ–‡ä»¶
    
    Args:
        url: ä¸‹è½½é“¾æ¥
        file_path: ä¿å­˜è·¯å¾„
        check_existing: æ˜¯å¦æ£€æŸ¥å·²å­˜åœ¨çš„æ–‡ä»¶ï¼ˆé»˜è®¤Trueï¼‰
    
    Returns:
        ä¸‹è½½æ˜¯å¦æˆåŠŸ
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': 'https://www.bilibili.com',
        }
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if check_existing and os.path.exists(file_path):
            existing_size = os.path.getsize(file_path)
            print(f"\n  â­ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {os.path.basename(file_path)} ({existing_size / 1024 / 1024:.2f} MB)")
            return True
        
        req = urllib.request.Request(url, headers=headers)
        
        with urllib.request.urlopen(req, timeout=300) as response:
            total_size = int(response.headers.get('Content-Length', 0))
            downloaded = 0
            
            # æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼šå¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œä»æ–­ç‚¹ç»§ç»­
            file_mode = 'ab' if os.path.exists(file_path) else 'wb'
            existing_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
            
            if existing_size > 0:
                print(f"\n  ğŸ“ æ£€æµ‹åˆ°å·²ä¸‹è½½çš„éƒ¨åˆ†æ–‡ä»¶ï¼Œä»æ–­ç‚¹ç»§ç»­...")
                headers['Range'] = f'bytes={existing_size}-'
                req = urllib.request.Request(url, headers=headers)
                downloaded = existing_size
            
            with open(file_path, file_mode) as f:
                while True:
                    chunk = response.read(1024 * 1024)
                    if not chunk:
                        break
                    
                    f.write(chunk)
                    downloaded += len(chunk)
                    
                    if total_size > 0:
                        progress = ((existing_size + downloaded) / (existing_size + total_size)) * 100 if existing_size > 0 else (downloaded / total_size) * 100
                        print(f"  è¿›åº¦: {progress:.1f}%", end='\r')
            
            file_size = os.path.getsize(file_path)
            print(f"\n  âœ“ å®Œæˆ! å¤§å°: {file_size / 1024 / 1024:.2f} MB")
            return True
            
    except Exception as e:
        print(f"\n  âœ— ä¸‹è½½å¤±è´¥: {e}")
        return False


async def main():
    parser = argparse.ArgumentParser(
        description='Bilibiliè§†é¢‘ä¸‹è½½å™¨ - å…¨è‡ªåŠ¨ç‰ˆï¼ˆæ”¯æŒè‡ªåŠ¨åˆå¹¶ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python scripts/download.py "https://www.bilibili.com/video/BV1mZrKBAEHf/"
  python scripts/download.py "BV1mZrKBAEHf" -o ./downloads
  python scripts/download.py "BV1mZrKBAEHf" --no-merge  # ä¸è‡ªåŠ¨åˆå¹¶
  python scripts/download.py "BV1mZrKBAEHf" --page 0  # åªä¸‹è½½ç¬¬1ä¸ªåˆ†P

è¯´æ˜:
  æœ¬è„šæœ¬ä½¿ç”¨bilibili-apiåº“ç›´æ¥ä»Bç«™APIä¸‹è½½è§†é¢‘
  è‡ªåŠ¨ä¸‹è½½éŸ³è§†é¢‘å¹¶ä½¿ç”¨ffmpegåˆå¹¶
  å¦‚æœæœªå®‰è£…ffmpegï¼Œå°†æä¾›åˆå¹¶å‘½ä»¤
  æ”¯æŒç™»å½•åä¸‹è½½é«˜æ¸…ç”»è´¨ï¼ˆéœ€é…ç½®config.iniï¼‰
        """
    )
    
    parser.add_argument('url', help='Bilibiliè§†é¢‘é“¾æ¥æˆ–BVå·')
    parser.add_argument('-o', '--output', default=None, help='ä¸‹è½½è¾“å‡ºç›®å½• (é»˜è®¤: å½“å‰å·¥ä½œç›®å½•ä¸‹çš„downloadsæ–‡ä»¶å¤¹)')
    parser.add_argument('--no-merge', action='store_true', help='ç¦ç”¨è‡ªåŠ¨åˆå¹¶éŸ³è§†é¢‘')
    parser.add_argument('--page', type=int, default=None, help='æŒ‡å®šä¸‹è½½çš„åˆ†Pç¼–å·ï¼ˆä»0å¼€å§‹ï¼‰ï¼Œä¸æŒ‡å®šåˆ™ä¸‹è½½æ‰€æœ‰åˆ†P')
    parser.add_argument('--threads', type=int, default=3, help='å¹¶è¡Œä¸‹è½½çš„çº¿ç¨‹æ•° (é»˜è®¤: 3)')
    
    args = parser.parse_args()

    # ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•çš„ç»å¯¹è·¯å¾„ä½œä¸ºé»˜è®¤ä¸‹è½½ç›®å½•
    default_output = os.path.abspath(os.path.join(os.getcwd(), 'downloads'))

    # æå–BVå·
    bvid = extract_bvid(args.url)
    if not bvid:
        print("[ERROR] æ— æ³•æå–BVå·")
        sys.exit(1)

    # ç¡®å®šè¾“å‡ºç›®å½•ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šï¼Œå¦åˆ™ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•çš„downloadsæ–‡ä»¶å¤¹ï¼‰
    if args.output and args.output != './downloads':
        output_dir = os.path.abspath(args.output)
    else:
        output_dir = default_output

    # ä¸‹è½½ï¼ˆè‡ªåŠ¨åˆå¹¶ï¼Œé™¤éæŒ‡å®š--no-mergeï¼‰
    auto_merge = not args.no_merge
    success = await download_video(bvid, output_dir, auto_merge, page_index=args.page, threads=args.threads)
    
    if not success:
        sys.exit(1)


if __name__ == '__main__':
    asyncio.run(main())
